import asyncio
import queue

import numpy as np
from aiortc import MediaStreamTrack

from src.audio.type import AudioType
from src.utils.logger import logger


class AudioStreamTrack(MediaStreamTrack):
    """è‡ªå®šä¹‰éŸ³é¢‘æµè½¨é“ï¼Œç”¨äºå‘é€éŸ³é¢‘æ•°æ®ç»™æµè§ˆå™¨"""

    kind = "audio"

    def __init__(self):
        super().__init__()
        self.audio_queue = queue.Queue(maxsize=200)  # é€‚ä¸­çš„é˜Ÿåˆ—å¤§å°ï¼Œé¿å…éŸ³é¢‘ä¸¢å¤±
        self._timestamp = 0
        self._sample_rate = 48000  # 48kHzï¼Œä¸æµè§ˆå™¨åŒ¹é…
        self._samples_per_frame = int(self._sample_rate * 0.02)  # 20ms frames
        self._is_running = True

    def stop(self):
        """åœæ­¢éŸ³é¢‘è½¨é“"""
        self._is_running = False
        # æ¸…ç©ºé˜Ÿåˆ—
        while not self.audio_queue.empty():
            try:
                self.audio_queue.get_nowait()
            except queue.Empty:
                break

    async def recv(self):
        """æ¥æ”¶éŸ³é¢‘å¸§"""
        # å¦‚æœå·²åœæ­¢ï¼Œè¿”å›ç©ºå¸§
        if not self._is_running:
            return None

        try:
            # ä»é˜Ÿåˆ—è·å–é¢„å¤„ç†çš„OPUSå¸§æ•°æ®
            frame_data = await asyncio.get_event_loop().run_in_executor(None, self.audio_queue.get, True, 1.0)
            # logger.debug(f"ğŸ§ ä»é˜Ÿåˆ—è·å–OPUSå¸§æ•°æ®: {len(frame_data) if frame_data else 0}å­—èŠ‚")

            if frame_data is None or len(frame_data) == 0:
                # ç”Ÿæˆé™éŸ³å¸§
                samples = np.zeros(960, dtype=np.int16)  # logger.debug(f"ğŸ”‡ ç”Ÿæˆé™éŸ³å¸§: 960æ ·æœ¬")
            else:
                # ç›´æ¥ä½¿ç”¨é¢„å¤„ç†çš„int16æ•°æ®
                samples = np.frombuffer(frame_data, dtype=np.int16)  # logger.debug(f"ğŸµ ä½¿ç”¨é¢„å¤„ç†å¸§: {len(samples)}æ ·æœ¬")

            # åˆ›å»ºéŸ³é¢‘å¸§
            from av import AudioFrame
            from fractions import Fraction

            frame = AudioFrame(format="s16", layout="mono", samples=960)
            frame.sample_rate = 48000

            # è®¡ç®—æ—¶é—´æˆ³
            import time
            current_time = time.time()
            if not hasattr(self, '_start_time'):
                self._start_time = current_time
                self._timestamp = 0

            frame.pts = self._timestamp
            frame.time_base = Fraction(1, 48000)

            # å¡«å……éŸ³é¢‘æ•°æ®ï¼ˆç¡®ä¿960æ ·æœ¬ï¼‰
            if len(samples) < 960:
                padding = np.zeros(960 - len(samples), dtype=np.int16)
                samples = np.concatenate([samples, padding])
            elif len(samples) > 960:
                samples = samples[:960]

            frame.planes[0].update(samples.tobytes())
            self._timestamp += 960

            # logger.debug(f"ğŸµ åˆ›å»ºOPUSå¸§: 960æ ·æœ¬, PTS={frame.pts}")
            return frame

        except queue.Empty:
            # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œç”Ÿæˆé™éŸ³å¸§
            samples = np.zeros(self._samples_per_frame, dtype=np.int16)
            from av import AudioFrame
            from fractions import Fraction
            frame = AudioFrame(format="s16", layout="mono", samples=self._samples_per_frame)
            frame.sample_rate = self._sample_rate
            frame.pts = self._timestamp
            frame.time_base = Fraction(1, self._sample_rate)
            frame.planes[0].update(samples.tobytes())
            self._timestamp += self._samples_per_frame
            return frame
        except Exception as e:
            logger.debug(f"éŸ³é¢‘å¸§ç”Ÿæˆé”™è¯¯: {e}")
            # è¿”å›é™éŸ³å¸§
            samples = np.zeros(self._samples_per_frame, dtype=np.int16)
            from av import AudioFrame
            from fractions import Fraction
            frame = AudioFrame(format="s16", layout="mono", samples=self._samples_per_frame)
            frame.sample_rate = self._sample_rate
            frame.pts = self._timestamp
            frame.time_base = Fraction(1, self._sample_rate)
            frame.planes[0].update(samples.tobytes())
            self._timestamp += self._samples_per_frame
            return frame

    def add_audio_data(self, audio_data: bytes, audio_type: AudioType):
        """æ·»åŠ éŸ³é¢‘æ•°æ®åˆ°å‘é€é˜Ÿåˆ—ï¼Œåˆ†å‰²æˆOPUSå¸§"""
        if not self._is_running:
            return

        try:
            # å¤„ç†éŸ³é¢‘æ•°æ®å¹¶åˆ†å‰²æˆå¤šä¸ªOPUSå¸§
            self._process_and_split_audio(audio_data, audio_type)
        except Exception as e:
            logger.error(f"âŒ å¤„ç†éŸ³é¢‘æ•°æ®å¤±è´¥: {e}")

    def _process_and_split_audio(self, audio_data: bytes, audio_type: AudioType):
        if audio_type == AudioType.pcm:
            self.audio_queue.put_nowait(audio_data)
            return

        """å¤„ç†éŸ³é¢‘æ•°æ®å¹¶åˆ†å‰²æˆOPUSæ ‡å‡†å¸§"""
        # è‡ªåŠ¨æ£€æµ‹éŸ³é¢‘æ ¼å¼å¹¶è§£æ
        if len(audio_data) % 4 == 0 and len(audio_data) % 2 == 0:
            # å°è¯•float32æ ¼å¼ï¼ˆç«å±±å¼•æ“TTSåŸç”Ÿæ ¼å¼ï¼‰
            try:
                samples_f32 = np.frombuffer(audio_data, dtype=np.float32)
                max_val = np.max(np.abs(samples_f32)) if len(samples_f32) > 0 else 0.0

                if 0.001 <= max_val <= 1.5:  # float32å…¸å‹èŒƒå›´
                    samples = np.clip(samples_f32, -1.0, 1.0)
                    samples = (samples * 32767).astype('int16')
                    logger.debug(f"ğŸ” æ£€æµ‹ä¸ºfloat32æ ¼å¼: {len(audio_data)}å­—èŠ‚, æœ€å¤§å€¼={max_val:.6f}")
                else:
                    # å¯èƒ½æ˜¯int16æ ¼å¼ï¼ˆOGGè½¬æ¢åï¼‰
                    samples = np.frombuffer(audio_data, dtype=np.int16)
                    logger.debug(
                        f"ğŸ” æ£€æµ‹ä¸ºint16æ ¼å¼: {len(audio_data)}å­—èŠ‚, æœ€å¤§å€¼={np.max(np.abs(samples)) if len(samples) > 0 else 0}"
                        )
            except Exception:
                # è§£æå¤±è´¥ï¼ŒæŒ‰int16å¤„ç†
                samples = np.frombuffer(audio_data[:len(audio_data) // 2 * 2], dtype=np.int16)
                logger.debug(f"ğŸ” è§£æå¤±è´¥ï¼ŒæŒ‰int16å¤„ç†: {len(audio_data)}å­—èŠ‚")
        else:
            # é•¿åº¦ä¸æ˜¯4çš„å€æ•°ï¼Œåªèƒ½æ˜¯int16
            samples = np.frombuffer(audio_data[:len(audio_data) // 2 * 2], dtype=np.int16)
            logger.debug(f"ğŸ” æŒ‰int16å¤„ç†: {len(audio_data)}å­—èŠ‚")

        # é‡é‡‡æ ·åˆ°48kHz (ä»24kHz)
        target_length = int(len(samples) * 48000 / 24000)
        if target_length > 0:
            indices = np.linspace(0, len(samples) - 1, target_length)
            samples = np.interp(indices, range(len(samples)), samples).astype('int16')

        # åˆ†å‰²æˆ960æ ·æœ¬çš„OPUSå¸§
        opus_frame_size = 960
        for i in range(0, len(samples), opus_frame_size):
            frame_samples = samples[i:i + opus_frame_size]

            # å¦‚æœä¸è¶³960æ ·æœ¬ï¼Œå¡«å……é›¶
            if len(frame_samples) < opus_frame_size:
                padding = np.zeros(opus_frame_size - len(frame_samples), dtype=np.int16)
                frame_samples = np.concatenate([frame_samples, padding])

            # å°†å¸§æ•°æ®è½¬æ¢ä¸ºbyteså¹¶åŠ å…¥é˜Ÿåˆ—
            frame_bytes = frame_samples.tobytes()

            # æ¸…ç†æ—§æ•°æ®é¿å…å»¶è¿Ÿç´¯ç§¯
            while self.audio_queue.qsize() > 100:
                try:
                    self.audio_queue.get_nowait()  # logger.debug("æ¸…ç†æ—§éŸ³é¢‘æ•°æ®ä»¥å‡å°‘å»¶è¿Ÿ")
                except queue.Empty:
                    break

            try:
                self.audio_queue.put_nowait(
                    frame_bytes
                    )
                # logger.debug(f"æ·»åŠ OPUSå¸§åˆ°é˜Ÿåˆ—: {len(frame_bytes)}å­—èŠ‚ï¼Œé˜Ÿåˆ—å¤§å°: {self.audio_queue.qsize()}")
            except queue.Full:
                logger.debug("âš ï¸ éŸ³é¢‘å‘é€é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæ•°æ®")
                break
