import asyncio
import queue
from typing import Dict, Any, Optional, Callable

import numpy as np
from aiortc import RTCPeerConnection, RTCSessionDescription, RTCIceCandidate, MediaStreamTrack

AIORTC_AVAILABLE = True

from .webrtc_signaling import WebRTCSignalingServer
from .logger import logger


class AudioStreamTrack(MediaStreamTrack):
    """è‡ªå®šä¹‰éŸ³é¢‘æµè½¨é“ï¼Œç”¨äºå‘é€éŸ³é¢‘æ•°æ®ç»™æµè§ˆå™¨"""

    kind = "audio"

    def __init__(self):
        super().__init__()
        self.audio_queue = queue.Queue(maxsize=50)  # é™åˆ¶é˜Ÿåˆ—å¤§å°
        self._timestamp = 0
        self._sample_rate = 48000  # 48kHzï¼Œä¸æµè§ˆå™¨åŒ¹é…
        self._samples_per_frame = int(self._sample_rate * 0.02)  # 20ms frames

    async def recv(self):
        """æ¥æ”¶éŸ³é¢‘å¸§"""
        try:
            # ä»é˜Ÿåˆ—è·å–éŸ³é¢‘æ•°æ®
            audio_data = await asyncio.get_event_loop().run_in_executor(None, self.audio_queue.get, True, 1.0)

            if audio_data is None:
                # ç”Ÿæˆé™éŸ³å¸§
                samples = np.zeros(self._samples_per_frame, dtype=np.int16)
            else:
                # è½¬æ¢éŸ³é¢‘æ•°æ®ä¸ºnumpy array
                samples = np.frombuffer(audio_data, dtype=np.int16)

                # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰éŸ³é¢‘æ•°æ®
                if len(samples) == 0:
                    samples = np.zeros(self._samples_per_frame, dtype=np.int16)
                else:
                    # é€‚åº¦é™ä½éŸ³é‡é¿å…çˆ†éŸ³ï¼Œä½†ä¿æŒå¯å¬æ€§
                    samples = (samples * 0.3).astype('int16')

                    # é‡é‡‡æ ·ä»16kHzåˆ°48kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
                    target_length = int(len(samples) * 48000 / 16000)
                    if target_length > 0:
                        indices = np.linspace(0, len(samples) - 1, target_length)
                        samples = np.interp(indices, range(len(samples)), samples).astype('int16')

                    # å¦‚æœæ•°æ®ä¸å¤Ÿä¸€å¸§ï¼Œç”¨é›¶å¡«å……
                    if len(samples) < self._samples_per_frame:
                        padding = np.zeros(self._samples_per_frame - len(samples), dtype=np.int16)
                        samples = np.concatenate([samples, padding])
                    elif len(samples) > self._samples_per_frame:
                        # å¦‚æœæ•°æ®å¤ªå¤šï¼Œæˆªå–å‰é¢éƒ¨åˆ†
                        samples = samples[:self._samples_per_frame]

                    # éŸ³é‡æ ‡å‡†åŒ–ï¼Œç¡®ä¿ä¸ä¼šçˆ†éŸ³ä½†ä¿æŒæ¸…æ™°
                    max_val = np.max(np.abs(samples))
                    if max_val > 16000:  # å¦‚æœéŸ³é‡è¿‡å¤§ï¼Œè¿›è¡Œæ ‡å‡†åŒ–
                        samples = (samples * 16000 / max_val).astype('int16')
                    elif max_val < 1000:  # å¦‚æœéŸ³é‡è¿‡å°ï¼Œé€‚åº¦æ”¾å¤§
                        samples = (samples * 1.5).astype('int16')

            # åˆ›å»ºéŸ³é¢‘å¸§
            from av import AudioFrame
            from fractions import Fraction
            frame = AudioFrame(format="s16", layout="mono", samples=self._samples_per_frame)
            frame.sample_rate = self._sample_rate
            frame.pts = self._timestamp
            frame.time_base = Fraction(1, self._sample_rate)

            # å¡«å……éŸ³é¢‘æ•°æ®
            frame.planes[0].update(samples.tobytes())

            self._timestamp += self._samples_per_frame
            return frame

        except queue.Empty:
            # å¦‚æœé˜Ÿåˆ—ä¸ºç©ºï¼Œç”Ÿæˆé™éŸ³å¸§
            samples = np.zeros(self._samples_per_frame, dtype=np.int16)
            from av import AudioFrame
            from fractions import Fraction
            frame = AudioFrame(format="s16", layout="mono", samples=self._samples_per_frame)
            frame.sample_rate = self._sample_rate
            frame.pts = self._timestamp
            frame.time_base = Fraction(1, self._sample_rate)
            frame.planes[0].update(samples.tobytes())
            self._timestamp += self._samples_per_frame
            return frame
        except Exception as e:
            logger.debug(f"éŸ³é¢‘å¸§ç”Ÿæˆé”™è¯¯: {e}")
            # è¿”å›é™éŸ³å¸§
            samples = np.zeros(self._samples_per_frame, dtype=np.int16)
            from av import AudioFrame
            from fractions import Fraction
            frame = AudioFrame(format="s16", layout="mono", samples=self._samples_per_frame)
            frame.sample_rate = self._sample_rate
            frame.pts = self._timestamp
            frame.time_base = Fraction(1, self._sample_rate)
            frame.planes[0].update(samples.tobytes())
            self._timestamp += self._samples_per_frame
            return frame

    def add_audio_data(self, audio_data: bytes):
        """æ·»åŠ éŸ³é¢‘æ•°æ®åˆ°å‘é€é˜Ÿåˆ—"""
        try:
            # æ¸…ç†æ—§æ•°æ®é¿å…å»¶è¿Ÿç´¯ç§¯ï¼Œä¿æŒè¾ƒçŸ­é˜Ÿåˆ—
            while self.audio_queue.qsize() > 5:
                try:
                    self.audio_queue.get_nowait()
                    logger.debug("æ¸…ç†æ—§éŸ³é¢‘æ•°æ®ä»¥å‡å°‘å»¶è¿Ÿ")
                except queue.Empty:
                    break

            self.audio_queue.put_nowait(audio_data)
            logger.debug(f"æ·»åŠ éŸ³é¢‘æ•°æ®åˆ°é˜Ÿåˆ—: {len(audio_data)}å­—èŠ‚ï¼Œé˜Ÿåˆ—å¤§å°: {self.audio_queue.qsize()}")
        except queue.Full:
            logger.warning("âš ï¸ éŸ³é¢‘å‘é€é˜Ÿåˆ—å·²æ»¡ï¼Œä¸¢å¼ƒæ•°æ®")


class WebRTCManager:
    """WebRTCç®¡ç†å™¨ï¼Œå¤„ç†ä¸æµè§ˆå™¨çš„WebRTCè¿æ¥"""

    def __init__(self, signaling_host: str = "localhost", signaling_port: int = 8765):
        if not AIORTC_AVAILABLE:
            raise ImportError("aiortcåº“æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install aiortc")

        self.signaling_server = WebRTCSignalingServer(signaling_host, signaling_port)
        self.peer_connections: Dict[str, RTCPeerConnection] = {}
        self.audio_tracks: Dict[str, AudioStreamTrack] = {}

        # éŸ³é¢‘å¤„ç†å›è°ƒ
        self.audio_input_callback: Optional[Callable[[bytes], None]] = None

        # è®¾ç½®ä¿¡ä»¤æœåŠ¡å™¨å›è°ƒ
        self.signaling_server.set_callbacks(on_offer=self.handle_offer,
            on_answer=self.handle_answer,
            on_ice_candidate=self.handle_ice_candidate,
            on_client_connected=self.handle_client_connected,
            on_client_disconnected=self.handle_client_disconnected)

    async def start(self):
        """å¯åŠ¨WebRTCç®¡ç†å™¨"""
        logger.info("ğŸš€ å¯åŠ¨WebRTCç®¡ç†å™¨")
        await self.signaling_server.start()

    async def stop(self):
        """åœæ­¢WebRTCç®¡ç†å™¨"""
        logger.info("ğŸ›‘ åœæ­¢WebRTCç®¡ç†å™¨")

        # å…³é—­æ‰€æœ‰peer connections
        for pc in self.peer_connections.values():
            await pc.close()

        await self.signaling_server.stop()

    def handle_client_connected(self, client_id: str):
        """å¤„ç†å®¢æˆ·ç«¯è¿æ¥"""
        logger.info(f"ğŸ”— WebRTCå®¢æˆ·ç«¯è¿æ¥: {client_id}")

        # åˆ›å»ºæ–°çš„RTCPeerConnection
        pc = RTCPeerConnection()
        self.peer_connections[client_id] = pc

        # åˆ›å»ºéŸ³é¢‘è½¨é“ç”¨äºå‘é€éŸ³é¢‘ç»™æµè§ˆå™¨
        audio_track = AudioStreamTrack()
        self.audio_tracks[client_id] = audio_track
        pc.addTrack(audio_track)

        # è®¾ç½®è¿æ¥çŠ¶æ€å˜åŒ–å›è°ƒ
        @pc.on("connectionstatechange")
        async def on_connectionstatechange():
            state = pc.connectionState
            logger.info(f"ğŸ”„ è¿æ¥çŠ¶æ€å˜åŒ–: {client_id} -> {state}")
            
            if state == "failed":
                logger.error(f"âŒ WebRTCè¿æ¥å¤±è´¥: {client_id}")
            elif state == "disconnected":
                logger.warning(f"âš ï¸ WebRTCè¿æ¥æ–­å¼€: {client_id}")
            elif state == "closed":
                logger.info(f"ğŸ”Œ WebRTCè¿æ¥å·²å…³é—­: {client_id}")
                # æ¸…ç†èµ„æº
                if client_id in self.audio_tracks:
                    del self.audio_tracks[client_id]
                    logger.debug(f"ğŸ§¹ å·²æ¸…ç†å®¢æˆ·ç«¯éŸ³é¢‘è½¨é“: {client_id}")
            elif state == "connected":
                logger.info(f"âœ… WebRTCè¿æ¥å·²å»ºç«‹: {client_id}")

        # è®¾ç½®æ¥æ”¶éŸ³é¢‘è½¨é“å›è°ƒ
        @pc.on("track")
        def on_track(track):
            logger.info(f"ğŸ¤ æ¥æ”¶åˆ°éŸ³é¢‘è½¨é“: {client_id} -> {track.kind}")
            if track.kind == "audio":
                # è®°å½•éŸ³é¢‘è½¨é“ï¼Œç”¨äºé‡è¿æ—¶çš„æ¸…ç†
                self._track_handlers = getattr(self, '_track_handlers', {})
                task = asyncio.create_task(self.process_audio_track_with_recovery(client_id, track))
                self._track_handlers[client_id] = task

    def handle_client_disconnected(self, client_id: str):
        """å¤„ç†å®¢æˆ·ç«¯æ–­å¼€è¿æ¥"""
        logger.info(f"ğŸ”Œ WebRTCå®¢æˆ·ç«¯æ–­å¼€: {client_id}")

        # å–æ¶ˆéŸ³é¢‘è½¨é“å¤„ç†ä»»åŠ¡
        if hasattr(self, '_track_handlers') and client_id in self._track_handlers:
            task = self._track_handlers[client_id]
            if not task.done():
                task.cancel()
                logger.debug(f"ğŸ›‘ å·²å–æ¶ˆéŸ³é¢‘è½¨é“å¤„ç†ä»»åŠ¡: {client_id}")
            del self._track_handlers[client_id]

        # æ¸…ç†èµ„æº
        if client_id in self.peer_connections:
            try:
                asyncio.create_task(self.peer_connections[client_id].close())
            except Exception as e:
                logger.debug(f"å…³é—­peer connectionæ—¶å‡ºé”™: {e}")
            del self.peer_connections[client_id]

        if client_id in self.audio_tracks:
            del self.audio_tracks[client_id]
            
        logger.debug(f"ğŸ§¹ å·²æ¸…ç†å®¢æˆ·ç«¯æ‰€æœ‰èµ„æº: {client_id}")

    async def handle_offer(self, client_id: str, data: Dict[str, Any]):
        """å¤„ç†WebRTC Offer"""
        logger.info(f"ğŸ“¨ æ”¶åˆ°Offer: {client_id}")

        if client_id not in self.peer_connections:
            logger.error(f"âŒ å®¢æˆ·ç«¯è¿æ¥ä¸å­˜åœ¨: {client_id}")
            return

        pc = self.peer_connections[client_id]

        try:
            # è®¾ç½®è¿œç¨‹æè¿°
            offer = RTCSessionDescription(sdp=data["sdp"]["sdp"], type=data["sdp"]["type"])
            await pc.setRemoteDescription(offer)

            # åˆ›å»ºç­”æ¡ˆ
            answer = await pc.createAnswer()
            await pc.setLocalDescription(answer)

            # å‘é€ç­”æ¡ˆç»™å®¢æˆ·ç«¯
            await self.signaling_server.send_answer(client_id, {"type": answer.type, "sdp": answer.sdp
            })

            logger.info(f"ğŸ“¤ å‘é€Answer: {client_id}")

        except Exception as e:
            logger.error(f"âŒ å¤„ç†Offeré”™è¯¯: {e}")

    async def handle_answer(self, client_id: str, data: Dict[str, Any]):
        """å¤„ç†WebRTC Answer"""
        logger.info(f"ğŸ“¨ æ”¶åˆ°Answer: {client_id}")  # é€šå¸¸æœåŠ¡å™¨ç«¯ä¸éœ€è¦å¤„ç†Answer

    async def handle_ice_candidate(self, client_id: str, data: Dict[str, Any]):
        """å¤„ç†ICEå€™é€‰"""
        logger.debug(f"ğŸ“¨ æ”¶åˆ°ICEå€™é€‰: {client_id}")

        if client_id not in self.peer_connections:
            logger.error(f"âŒ å®¢æˆ·ç«¯è¿æ¥ä¸å­˜åœ¨: {client_id}")
            return

        pc = self.peer_connections[client_id]

        try:
            candidate_data = data["candidate"]
            if candidate_data and candidate_data.get("candidate"):
                # è§£æICEå€™é€‰å­—ç¬¦ä¸²
                candidate_string = candidate_data["candidate"]
                sdp_mid = candidate_data.get("sdpMid")
                sdp_mline_index = candidate_data.get("sdpMLineIndex")

                # æ‰‹åŠ¨è§£æå€™é€‰å­—ç¬¦ä¸² (ä¾‹å¦‚: "candidate:1 1 UDP 2113667326 192.168.1.1 54400 typ host")
                parts = candidate_string.split()
                if len(parts) >= 8:
                    foundation = parts[0].split(":")[1] if ":" in parts[0] else parts[0]
                    component = int(parts[1])
                    protocol = parts[2].lower()
                    priority = int(parts[3])
                    ip = parts[4]
                    port = int(parts[5])
                    typ = parts[7] if len(parts) > 7 else "host"

                    # åˆ›å»ºRTCIceCandidateå¯¹è±¡
                    candidate = RTCIceCandidate(foundation=foundation,
                        component=component,
                        protocol=protocol,
                        priority=priority,
                        ip=ip,
                        port=port,
                        type=typ,
                        sdpMid=sdp_mid,
                        sdpMLineIndex=sdp_mline_index)

                    await pc.addIceCandidate(candidate)
                else:
                    logger.warning(f"âš ï¸ æ— æ•ˆçš„ICEå€™é€‰æ ¼å¼: {candidate_string}")
            else:
                # ç©ºå€™é€‰è¡¨ç¤ºå€™é€‰æ”¶é›†ç»“æŸ
                await pc.addIceCandidate(None)
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ICEå€™é€‰é”™è¯¯: {e}")

    async def process_audio_track(self, client_id: str, track):
        """å¤„ç†æ¥æ”¶åˆ°çš„éŸ³é¢‘è½¨é“"""
        logger.info(f"ğŸµ å¼€å§‹å¤„ç†éŸ³é¢‘è½¨é“: {client_id}")

        try:
            while True:
                try:
                    # è®¾ç½®æ¥æ”¶è¶…æ—¶ï¼Œé¿å…æ— é™ç­‰å¾…
                    frame = await asyncio.wait_for(track.recv(), timeout=5.0)
                    
                    if frame is None:
                        logger.debug(f"âš ï¸ æ¥æ”¶åˆ°ç©ºéŸ³é¢‘å¸§ï¼Œè·³è¿‡å¤„ç†")
                        continue
                        
                    # logger.debug(f"ğŸ¤ æ”¶åˆ°éŸ³é¢‘å¸§: {frame.format}, é‡‡æ ·ç‡: {frame.sample_rate}, æ ·æœ¬æ•°: {frame.samples}")

                    # è½¬æ¢éŸ³é¢‘å¸§ä¸ºnumpyæ•°ç»„
                    audio_array = frame.to_ndarray()
                    
                    if audio_array is None or audio_array.size == 0:
                        logger.debug(f"âš ï¸ éŸ³é¢‘æ•°ç»„ä¸ºç©ºï¼Œè·³è¿‡å¤„ç†")
                        continue
                        
                    # logger.debug(f"ğŸ¤ éŸ³é¢‘æ•°ç»„å½¢çŠ¶: {audio_array.shape}, æ•°æ®ç±»å‹: {audio_array.dtype}")

                    # å¦‚æœæ˜¯å¤šç»´æ•°ç»„ï¼Œå±•å¹³ä¸ºä¸€ç»´ï¼ˆé€šé“åœ¨ç¬¬ä¸€ç»´ï¼‰
                    if len(audio_array.shape) > 1:
                        # å¦‚æœæ˜¯å¤šé€šé“ï¼Œå–ç¬¬ä¸€ä¸ªé€šé“æˆ–å¹³å‡
                        if audio_array.shape[0] > 1:
                            audio_array = audio_array[0]  # å–ç¬¬ä¸€ä¸ªé€šé“
                        else:
                            audio_array = audio_array.flatten()

                    # logger.debug(f"ğŸ¤ å±•å¹³åéŸ³é¢‘æ•°ç»„å½¢çŠ¶: {audio_array.shape}")

                    # è½¬æ¢ä¸º16ä½PCMæ ¼å¼ï¼ˆç«å±±å¼•æ“éœ€è¦çš„æ ¼å¼ï¼‰
                    if audio_array.dtype != 'int16':
                        # å¦‚æœæ˜¯æµ®ç‚¹æ ¼å¼ï¼Œè½¬æ¢ä¸ºint16
                        if audio_array.dtype.kind == 'f':
                            audio_array = (audio_array * 32767).astype('int16')
                        else:
                            audio_array = audio_array.astype('int16')

                    # é‡é‡‡æ ·åˆ°16kHzï¼ˆå¦‚æœéœ€è¦ï¼‰
                    if frame.sample_rate != 16000:
                        # ç®€å•çš„é‡é‡‡æ ·ï¼ˆç”Ÿäº§ç¯å¢ƒå»ºè®®ä½¿ç”¨æ›´å¥½çš„é‡é‡‡æ ·ç®—æ³•ï¼‰
                        target_length = int(len(audio_array) * 16000 / frame.sample_rate)
                        if target_length > 0:
                            indices = np.linspace(0, len(audio_array) - 1, target_length)
                            audio_array = np.interp(indices, range(len(audio_array)), audio_array).astype('int16')
                            # logger.debug(f"ğŸ¤ é‡é‡‡æ ·: {frame.sample_rate}Hz -> 16000Hz, é•¿åº¦: {len(audio_array)}")
                        else:
                            # logger.debug(f"âš ï¸ é‡é‡‡æ ·é•¿åº¦ä¸º0: åŸé•¿åº¦={len(audio_array)}, ç›®æ ‡é•¿åº¦={target_length}")
                            continue

                    audio_data = audio_array.tobytes()
                    # logger.debug(f"ğŸ¤ received audio data: {len(audio_data)} å­—èŠ‚")

                    # è°ƒç”¨éŸ³é¢‘è¾“å…¥å›è°ƒ
                    if self.audio_input_callback and len(audio_data) > 0:
                        self.audio_input_callback(audio_data)

                except asyncio.TimeoutError:
                    logger.debug(f"â° éŸ³é¢‘è½¨é“æ¥æ”¶è¶…æ—¶: {client_id}")
                    continue
                except Exception as e:
                    # æ£€æŸ¥æ˜¯å¦æ˜¯MediaStreamErrorï¼Œè¿™é€šå¸¸è¡¨ç¤ºæµå·²ç»“æŸ
                    if "MediaStreamError" in str(e):
                        logger.info(f"ğŸ”š éŸ³é¢‘æµå·²ç»“æŸ: {client_id}")
                        break
                    else:
                        logger.warning(f"âš ï¸ å¤„ç†éŸ³é¢‘å¸§é”™è¯¯: {e}")
                        continue

        except Exception as e:
            logger.error(f"âŒ å¤„ç†éŸ³é¢‘è½¨é“é”™è¯¯: {e}")
            import traceback
            logger.error(traceback.format_exc())
        finally:
            logger.info(f"ğŸ”š éŸ³é¢‘è½¨é“å¤„ç†ç»“æŸ: {client_id}")

    async def process_audio_track_with_recovery(self, client_id: str, track):
        """å¸¦æ¢å¤æœºåˆ¶çš„éŸ³é¢‘è½¨é“å¤„ç†"""
        max_retries = 3
        retry_count = 0
        
        while retry_count < max_retries:
            try:
                await self.process_audio_track(client_id, track)
                # å¦‚æœæ­£å¸¸ç»“æŸï¼Œè·³å‡ºé‡è¯•å¾ªç¯
                break
                
            except Exception as e:
                retry_count += 1
                logger.warning(f"âš ï¸ éŸ³é¢‘è½¨é“å¤„ç†å¤±è´¥ ({retry_count}/{max_retries}): {e}")
                
                if retry_count < max_retries:
                    # ç­‰å¾…ä¸€æ®µæ—¶é—´åé‡è¯•
                    await asyncio.sleep(1.0 * retry_count)
                    logger.info(f"ğŸ”„ é‡è¯•éŸ³é¢‘è½¨é“å¤„ç†: {client_id}")
                else:
                    logger.error(f"âŒ éŸ³é¢‘è½¨é“å¤„ç†æœ€ç»ˆå¤±è´¥: {client_id}")
                    break
        
        # æ¸…ç†ä»»åŠ¡è®°å½•
        if hasattr(self, '_track_handlers') and client_id in self._track_handlers:
            del self._track_handlers[client_id]

    def send_audio_to_client(self, client_id: str, audio_data: bytes):
        """å‘é€éŸ³é¢‘æ•°æ®ç»™æŒ‡å®šå®¢æˆ·ç«¯"""
        if client_id in self.audio_tracks:
            try:
                self.audio_tracks[client_id].add_audio_data(audio_data)
                logger.debug(f"âœ… éŸ³é¢‘æ•°æ®å·²å‘é€ç»™å®¢æˆ·ç«¯: {client_id}")
            except Exception as e:
                logger.error(f"âŒ å‘é€éŸ³é¢‘æ•°æ®ç»™å®¢æˆ·ç«¯å¤±è´¥ {client_id}: {e}")
        else:
            logger.warning(f"âš ï¸ å®¢æˆ·ç«¯éŸ³é¢‘è½¨é“ä¸å­˜åœ¨: {client_id}")

    def send_audio_to_all_clients(self, audio_data: bytes):
        """å‘é€éŸ³é¢‘æ•°æ®ç»™æ‰€æœ‰å®¢æˆ·ç«¯"""
        if not audio_data or len(audio_data) == 0:
            logger.debug("âš ï¸ è·³è¿‡ç©ºéŸ³é¢‘æ•°æ®")
            return
            
        active_clients = list(self.audio_tracks.keys())
        if not active_clients:
            logger.debug("âš ï¸ æ²¡æœ‰æ´»è·ƒçš„WebRTCå®¢æˆ·ç«¯")
            return
            
        logger.debug(f"ğŸ“¡ å‘ {len(active_clients)} ä¸ªå®¢æˆ·ç«¯å‘é€éŸ³é¢‘æ•°æ®: {len(audio_data)}å­—èŠ‚")
        for client_id in active_clients:
            self.send_audio_to_client(client_id, audio_data)

    def set_audio_input_callback(self, callback: Callable[[bytes], None]):
        """è®¾ç½®éŸ³é¢‘è¾“å…¥å›è°ƒå‡½æ•°"""
        self.audio_input_callback = callback

    def get_client_count(self) -> int:
        """è·å–å½“å‰è¿æ¥çš„å®¢æˆ·ç«¯æ•°é‡"""
        return len(self.peer_connections)
