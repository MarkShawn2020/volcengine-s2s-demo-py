import asyncio
import signal
import threading
import time
import uuid
from typing import Dict, Any

import src.io.webrtc.config
import src.io.websocket.config
import src.volcengine.config
from src import config
from src.client import RealtimeDialogClient
from src.io.io_base import IOBase
from src.utils.audio.audio_converter import OggToPcmConverter
from src.utils.audio.detect_audio_format import detect_audio_format
from src.utils.logger import logger
from src.volcengine.protocol import ServerEvent


class Orchestrator:
    """å¯¹è¯ä¼šè¯ç®¡ç†ç±» - é‡æ„ç‰ˆæœ¬"""

    def __init__(self, ws_config: Dict[str, Any], io_mode: str = None):
        self.session_id = str(uuid.uuid4())
        logger.info(f"ğŸš€ å¯åŠ¨å¯¹è¯ä¼šè¯ (ID: {self.session_id[:8]}...)")

        # WebSocketå®¢æˆ·ç«¯
        self.client = RealtimeDialogClient(config=ws_config, session_id=self.session_id)

        # ç¡®å®šIOæ¨¡å¼
        if io_mode is None:
            io_mode = config.IO_MODE
        self.io_mode = io_mode

        # åˆå§‹åŒ–éŸ³é¢‘IO
        self.audio_io = self._create_audio_io(io_mode)
        self.audio_io.set_audio_input_callback(self._handle_audio_input)

        # ä¼šè¯æ§åˆ¶
        self.is_running = True
        self.is_session_finished = False

        # ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._keyboard_signal)

        # éŸ³é¢‘è½¬æ¢å™¨
        output_config = src.volcengine.config.ogg_output_audio_config
        tts_config = src.volcengine.config.start_session_req.get("tts")
        if tts_config:
            tts_audio_config = tts_config.get("audio_config")
            if tts_audio_config:
                output_config = tts_audio_config

        self.ogg_converter = OggToPcmConverter(sample_rate=output_config['sample_rate'],
                                               channels=output_config['channels'])

        # å®æ—¶å­—å¹•æ˜¾ç¤º
        self.current_user_text = ""
        self.current_ai_text = ""
        self.conversation_history = []
        self.subtitle_lock = threading.Lock()
        self.is_user_speaking = False
        self.is_ai_responding = False
        self.last_displayed_ai_text = ""

        # é‡è¿æ§åˆ¶
        self._reconnecting = False
        self._reconnect_lock = None

    def _create_audio_io(self, io_mode: str) -> IOBase:
        """åˆ›å»ºéŸ³é¢‘IOå®ä¾‹"""
        if io_mode == "webrtc":
            from src.io.webrtc.webrtc_io import WebRTCIO
            return WebRTCIO(src.io.webrtc.config.webrtc_config)
        elif io_mode == "websocket":
            from src.io.websocket.websocket_io import WebsocketIO
            return WebsocketIO(src.io.websocket.config.socket_config)
        else:  # system
            from src.io.system.system_io import SystemIO
            return SystemIO({})

    def _handle_audio_input(self, audio_data: bytes) -> None:
        """å¤„ç†éŸ³é¢‘è¾“å…¥æ•°æ®"""
        if not self.is_running:
            return

        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡å‘é€éŸ³é¢‘æ•°æ®
        asyncio.create_task(self.client.task_request(audio_data))

    def _is_websocket_connected(self) -> bool:
        """æ£€æŸ¥WebSocketè¿æ¥çŠ¶æ€"""
        if not self.client or not self.client.ws:
            return False

        try:
            import websockets
            if hasattr(self.client.ws, 'state'):
                return self.client.ws.state == websockets.protocol.State.OPEN
            elif hasattr(self.client.ws, 'closed'):
                return not self.client.ws.closed
            else:
                return True
        except Exception as e:
            logger.debug(f"æ£€æŸ¥WebSocketçŠ¶æ€æ—¶å‡ºé”™: {e}")
            return False

    def handle_server_response(self, response: Dict[str, Any]) -> None:
        """å¤„ç†æœåŠ¡å™¨å“åº”"""
        if response == {}:
            return

        if response['message_type'] == 'SERVER_ACK':
            event = response.get('event', 0)

            if isinstance(response.get('payload_msg'), bytes):
                audio_data = response['payload_msg']

                if len(audio_data) == 0:
                    return

                if event == ServerEvent.TTS_RESPONSE:
                    logger.debug(f"ğŸµ æ”¶åˆ°TTSResponseéŸ³é¢‘æ•°æ®: {len(audio_data)}å­—èŠ‚")

                audio_format = detect_audio_format(audio_data)

                if audio_format == "ogg":
                    audio_data = self.ogg_converter.convert(audio_data)

                # é€šè¿‡éŸ³é¢‘IOå‘é€è¾“å‡º
                format_type = "ogg" if audio_format == "ogg" else "pcm"
                asyncio.create_task(self.audio_io.send_audio_output(audio_data, format_type))

            elif isinstance(response.get('payload_msg'), dict):
                ai_content = response.get('payload_msg', {}).get('content', '')
                if ai_content:
                    logger.debug(f"ğŸ¤– AIæ–‡æœ¬å›å¤(SERVER_ACK): '{ai_content}'")
                    self.current_ai_text += ai_content
                    self._display_subtitle(ai_text=self.current_ai_text, is_final=False)

        elif response['message_type'] == 'SERVER_FULL_RESPONSE':
            event = response.get('event', 'unknown')
            if logger.level <= 10:
                logger.debug(f'Event: {event}, Response: {response}\n')
            payload_msg = response.get('payload_msg', {})

            connection_events = [ServerEvent.CONNECTION_STARTED, ServerEvent.CONNECTION_FAILED,
                                 ServerEvent.CONNECTION_FINISHED, ServerEvent.SESSION_STARTED,
                                 ServerEvent.SESSION_FINISHED, ServerEvent.SESSION_FAILED]

            if event in connection_events:
                logger.info(f"ğŸ“¡ {ServerEvent(event).name}")
            else:
                event_name = ServerEvent(event).name if event in ServerEvent._value2member_map_ else f'Unknown({event})'
                logger.debug(f"ğŸ“¡ {event_name}")

            # å¤„ç†å„ç§æœåŠ¡å™¨äº‹ä»¶
            if event == ServerEvent.CONNECTION_STARTED:
                logger.info("ğŸ”— è¿æ¥å·²å»ºç«‹")
            elif event == ServerEvent.SESSION_STARTED:
                dialog_id = payload_msg.get('dialog_id', '')
                logger.info(f"ğŸš€ ä¼šè¯å·²å¯åŠ¨ (Dialog ID: {dialog_id[:8]}...)")
                asyncio.create_task(self.client.say_hello("ä½ å¥½ï¼Œæˆ‘æ˜¯ä½ çš„è¯­éŸ³åŠ©æ‰‹ï¼Œæœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"))
            elif event == ServerEvent.SESSION_FINISHED:
                logger.info("âœ… ä¼šè¯å·²ç»“æŸ")
            elif event == ServerEvent.TTS_ENDED:
                logger.debug("ğŸµ TTSéŸ³é¢‘åˆæˆç»“æŸ")
                self._finalize_conversation_turn()
            elif event == ServerEvent.ASR_INFO:
                self.ogg_converter.reset()
                logger.debug("å·²æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº (ç”¨æˆ·æ‰“æ–­)")
                self.is_user_speaking = True
                self.is_ai_responding = False
                self.current_user_text = ""
                self._update_console_display()
            elif event == ServerEvent.ASR_RESPONSE:
                results = payload_msg.get('results', [])
                if results and len(results) > 0:
                    text = results[0].get('text', '')
                    is_interim = results[0].get('is_interim', False)
                    if text and text.strip():
                        self.current_user_text = text
                        self._update_console_display()
                        logger.debug(f"ğŸ‘¤ ç”¨æˆ·è¯­éŸ³è¯†åˆ«: '{text}' (ä¸´æ—¶: {is_interim})")
            elif event == ServerEvent.ASR_ENDED:
                self.is_user_speaking = False
                if self.current_user_text and self.current_user_text.strip():
                    self._update_console_display(final_user=True)
                logger.debug("è¯­éŸ³è¯†åˆ«ç»“æŸ")
            elif event == ServerEvent.CHAT_RESPONSE:
                content = payload_msg.get('content', '')
                if content and content.strip():
                    if not self.is_ai_responding:
                        self.is_ai_responding = True
                        self.current_ai_text = ""
                        self.last_displayed_ai_text = ""
                    self.current_ai_text += content
                    if len(self.current_ai_text) - len(self.last_displayed_ai_text) >= 5 or content.endswith(('ã€‚', 'ï¼',
                                                                                                              'ï¼Ÿ', 'ï¼Œ',
                                                                                                              'ã€')):
                        self._update_console_display()
                    logger.debug(f"ğŸ¤– AIæ–‡æœ¬å›å¤: '{content}' â†’ æ€»è®¡: '{self.current_ai_text[:50]}...'")
            elif event == ServerEvent.CHAT_ENDED:
                logger.debug("ğŸ¤– AIæ–‡æœ¬å›å¤ç»“æŸ")
                self.is_ai_responding = False

        elif response['message_type'] == 'SERVER_ERROR':
            logger.error(f"æœåŠ¡å™¨é”™è¯¯: {response['payload_msg']}")
            raise Exception("æœåŠ¡å™¨é”™è¯¯")

    def _display_subtitle(self, ai_text: str = "", is_final: bool = False):
        """æ˜¾ç¤ºå­—å¹•"""
        pass  # ç®€åŒ–å®ç°

    def _clear_current_line(self):
        """æ¸…é™¤å½“å‰è¡Œ"""
        print("\r\033[K", end="", flush=True)

    def _update_console_display(self, final_user: bool = False, final_ai: bool = False):
        """æ›´æ–°æ§åˆ¶å°æ˜¾ç¤º"""
        with self.subtitle_lock:
            if final_user and self.current_user_text:
                self._clear_current_line()
                print(f"ğŸ‘¤ ç”¨æˆ·: {self.current_user_text}")
                return
            elif final_ai and self.current_ai_text:
                self._clear_current_line()
                print(f"ğŸ¤– AI: {self.current_ai_text}")
                self.last_displayed_ai_text = self.current_ai_text
                return

            if self.is_user_speaking and self.current_user_text:
                self._clear_current_line()
                display_text = self.current_user_text[
                               :150] + "..." if len(self.current_user_text) > 150 else self.current_user_text
                print(f"ğŸ‘¤ ç”¨æˆ·: {display_text}", end="", flush=True)
            elif self.is_ai_responding and self.current_ai_text:
                if self.current_ai_text != self.last_displayed_ai_text:
                    self._clear_current_line()
                    display_text = self.current_ai_text[
                                   :150] + "..." if len(self.current_ai_text) > 150 else self.current_ai_text
                    print(f"ğŸ¤– AI: {display_text}", end="", flush=True)
                    self.last_displayed_ai_text = self.current_ai_text
            elif not self.is_user_speaking and not self.is_ai_responding:
                self._clear_current_line()
                print("ğŸ™ï¸ è¯·è¯´è¯...", end="", flush=True)

    def _finalize_conversation_turn(self):
        """å®Œæˆä¸€è½®å¯¹è¯"""
        with self.subtitle_lock:
            if self.current_user_text or self.current_ai_text:
                if self.current_ai_text and self.current_ai_text != self.last_displayed_ai_text:
                    self._clear_current_line()
                    print(f"ğŸ¤– AI: {self.current_ai_text}")

                self.conversation_history.append({
                    'user': self.current_user_text,
                    'ai': self.current_ai_text,
                    'timestamp': time.time()
                })

                self.current_user_text = ""
                self.current_ai_text = ""
                self.last_displayed_ai_text = ""
                self.is_user_speaking = False
                self.is_ai_responding = False

                print(f"\n{'â”€' * 50}")
                print(f"ğŸ“Š ç¬¬{len(self.conversation_history)}è½®å¯¹è¯ | â° {time.strftime('%H:%M:%S')}")
                print(f"{'â”€' * 50}\n")
                print("ğŸ™ï¸ è¯·è¯´è¯...", end="", flush=True)

    def _keyboard_signal(self, sig, frame):
        logger.info("ğŸ‘‹ æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
        self.is_running = False

        # ç«‹å³åœæ­¢éŸ³é¢‘IOï¼Œé¿å…ç»§ç»­äº§ç”Ÿé”™è¯¯
        if self.audio_io and hasattr(self.audio_io, 'is_running'):
            self.audio_io.is_running = False
            
        # å¦‚æœæ˜¯WebRTCæ¨¡å¼ï¼Œç«‹å³åœæ­¢WebRTCç®¡ç†å™¨
        if self.io_mode == "webrtc" and self.audio_io and hasattr(self.audio_io, 'webrtc_manager'):
            if self.audio_io.webrtc_manager:
                self.audio_io.webrtc_manager.is_running = False

        # åˆ›å»ºä¸€ä¸ªæ–°çš„äº‹ä»¶å¾ªç¯æ¥å¤„ç†æ¸…ç†æ“ä½œ
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # å¦‚æœäº‹ä»¶å¾ªç¯æ­£åœ¨è¿è¡Œï¼Œåˆ›å»ºä»»åŠ¡
                asyncio.create_task(self._graceful_shutdown())
            else:
                # å¦‚æœäº‹ä»¶å¾ªç¯æœªè¿è¡Œï¼Œç›´æ¥è¿è¡Œ
                loop.run_until_complete(self._graceful_shutdown())
        except Exception as e:
            logger.error(f"ä¼˜é›…å…³é—­è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            import os
            os._exit(1)

    async def _graceful_shutdown(self):
        """ä¼˜é›…å…³é—­æ‰€æœ‰èµ„æº"""
        try:
            logger.info("å¼€å§‹ä¼˜é›…å…³é—­...")
            
            # åœæ­¢éŸ³é¢‘IO
            if self.audio_io:
                try:
                    await self.audio_io.stop()
                    self.audio_io.cleanup()
                except Exception as e:
                    logger.warning(f"åœæ­¢éŸ³é¢‘IOé”™è¯¯: {e}")

            # ä¼˜é›…å…³é—­WebSocketè¿æ¥
            if self.client:
                try:
                    await self.client.graceful_shutdown()
                except Exception as e:
                    logger.warning(f"ä¼˜é›…å…³é—­WebSocketé”™è¯¯: {e}")

            logger.info("âœ… ä¼˜é›…å…³é—­å®Œæˆ")
        except Exception as e:
            logger.error(f"ä¼˜é›…å…³é—­è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        finally:
            import os
            os._exit(0)

    async def receive_loop(self):
        try:
            while True:
                response = await self.client.receive_server_response()
                self.handle_server_response(response)
                if 'event' in response and (response['event'] == ServerEvent.SESSION_FINISHED or response[
                    'event'] == ServerEvent.SESSION_FAILED):
                    logger.info(f"æ¥æ”¶åˆ°ä¼šè¯ç»“æŸäº‹ä»¶: {ServerEvent(response['event']).name}({response['event']})")
                    self.is_session_finished = True
                    break
        except asyncio.CancelledError:
            logger.info("æ¥æ”¶ä»»åŠ¡å·²å–æ¶ˆ")
        except Exception as e:
            logger.error(f"æ¥æ”¶æ¶ˆæ¯é”™è¯¯: {e}")

    async def start(self) -> None:
        """å¯åŠ¨å¯¹è¯ä¼šè¯"""
        try:
            # åˆå§‹åŒ–é‡è¿é”
            self._reconnect_lock = asyncio.Lock()

            # å»ºç«‹WebSocketè¿æ¥
            await self.client.connect()

            # å¯åŠ¨æ¥æ”¶å¾ªç¯
            receive_task = asyncio.create_task(self.receive_loop())

            # å‘é€è¿æ¥å’Œä¼šè¯åˆå§‹åŒ–è¯·æ±‚
            await self.client.start_connection()
            await self.client.start_session()

            await asyncio.sleep(0.1)

            # å¯åŠ¨éŸ³é¢‘IO
            asyncio.create_task(self.audio_io.start())

            # ä¿æŒä¸»å¾ªç¯è¿è¡Œï¼Œç›‘æ§è¿æ¥çŠ¶æ€
            while self.is_running:
                await asyncio.sleep(0.5)

            # æ­£å¸¸ç»“æŸæ—¶ä¹Ÿä½¿ç”¨ä¼˜é›…å…³é—­
            await self.client.graceful_shutdown()
            logger.info(f"å¯¹è¯è¯·æ±‚æ—¥å¿—ID: {self.client.logid}")
        except Exception as e:
            logger.error(f"ä¼šè¯é”™è¯¯: {e}")
        finally:
            # ç¡®ä¿èµ„æºè¢«æ¸…ç†
            if self.audio_io:
                try:
                    await self.audio_io.stop()
                    self.audio_io.cleanup()
                except Exception as e:
                    logger.warning(f"æ¸…ç†éŸ³é¢‘IOèµ„æºé”™è¯¯: {e}")
            
            if self.client:
                try:
                    await self.client.close()
                except Exception as e:
                    logger.warning(f"æœ€ç»ˆå…³é—­WebSocketé”™è¯¯: {e}")
