import asyncio
import json
import logging
import signal
import threading
import time

from src.config import (ADAPTER_MODE, VOLCENGINE_WELCOME, )
from src.io_adapters.base import AdapterBase
from src.io_adapters.type import AdapterMode
from src.volcengine.client import VoicengineClient
from src.volcengine.config import ws_connect_config
from src.volcengine.protocol import ServerEvent

logger = logging.getLogger(__name__)


class Orchestrator:

    def __init__(self):
        # WebSocket --> voicengine å®¢æˆ·ç«¯
        self.volcengine_client = VoicengineClient(config=ws_connect_config)

        # åˆå§‹åŒ–éŸ³é¢‘IO
        self.audio_adapter = self._create_audio_adapter(ADAPTER_MODE)
        self.audio_adapter.set_on_prepared(self._request_say_hello)

        # ä¼šè¯æ§åˆ¶
        self.is_running = False
        self.is_session_finished = False
        self.is_stopping = False
        self._should_send_hello = False

        # ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._keyboard_signal)

        # å®æ—¶å­—å¹•æ˜¾ç¤º
        self.current_user_text = ""
        self.current_ai_text = ""
        self.conversation_history = []
        self.subtitle_lock = threading.Lock()
        self.is_user_speaking = False
        self.is_ai_responding = False
        self.last_displayed_ai_text = ""

    async def start(self) -> None:
        """å¯åŠ¨å¯¹è¯ä¼šè¯"""
        if self.is_running: return
        self.is_running = True
        logger.info("starting")
        try:

            logger.info("starting volcengine client")
            await self.volcengine_client.start()
            await self.volcengine_client.request_start_connection()
            await self.volcengine_client.request_start_session()
            logger.info("started volcengine client")

            await self.audio_adapter.start()

            async with asyncio.TaskGroup() as tg:
                logger.info("starting tasks")
                # æ ¹æ®å®˜æ–¹ä»£ç ç»éªŒ
                # receiver é‡Œä¸è¦åŠ ä»»ä½•çš„awaitï¼Œå› ä¸ºrecvæœ¬æ¥å°±åœ¨ç­‰
                # senderé‡Œè¦åŠ ä¸€ç‚¹awaitï¼Œå¦åˆ™cpuä¼šè¿‡é«˜
                tg.create_task(self.thread_server2client())
                tg.create_task(self.thread_client2server())
                logger.info("started tasks")
        except Exception as e:
            logger.error(f"failed to start, reason: {e}")
        finally:
            await self.stop()

    async def stop(self):
        if self.is_stopping: return
        self.is_stopping = True

        try:
            logger.info("stopping")
            async with asyncio.TaskGroup() as tg:
                tg.create_task(self.volcengine_client.stop())
                tg.create_task(self.audio_adapter.stop())
            logger.info("stopped")
        except Exception as e:
            logger.error(f"failed to stop, reason: {e}")

    async def thread_server2client(self):
        seq = 0
        try:
            while self.is_running and self.volcengine_client.is_active:
                seq += 1
                logger.debug(f"pulling ({seq})")
                response = await self.volcengine_client.on_response()
                if response is None:
                    # è¶…æ—¶æˆ–è¿æ¥é—®é¢˜ï¼Œç»§ç»­å¾ªç¯æ£€æŸ¥is_runningçŠ¶æ€
                    continue
                event = response.get('event', 'unknown')
                payload_msg = response.get('payload_msg')
                logger.debug(
                    f"ğŸ  <-- ğŸ“¡ [{ServerEvent(event).name}] Payload(type={type(payload_msg)}, size="
                    f"{len(payload_msg)})"
                    )
                if isinstance(payload_msg, dict):
                    logger.debug(json.dumps(payload_msg, indent=2, ensure_ascii=False))

                if response['message_type'] == 'SERVER_ACK':

                    if isinstance(payload_msg, bytes):
                        # ã€é‡è¦ã€‘å½“ä¸­æ§æ”¶åˆ°äº†AIéŸ³é¢‘ï¼Œäº¤ç»™ä»£ç†å™¨å¤„ç†
                        await self.audio_adapter.on_get_next_server_chunk(payload_msg)

                    elif isinstance(payload_msg, dict):
                        ai_content = payload_msg.get('content', '')
                        if ai_content:
                            logger.debug(f"ğŸ¤– AIæ–‡æœ¬å›å¤(SERVER_ACK): '{ai_content}'")
                            self.current_ai_text += ai_content
                            self._display_subtitle(ai_text=self.current_ai_text, is_final=False)

                elif response['message_type'] == 'SERVER_FULL_RESPONSE':

                    # å¤„ç†å„ç§æœåŠ¡å™¨äº‹ä»¶
                    if event == ServerEvent.CONNECTION_STARTED:
                        logger.info("ğŸ”— è¿æ¥å·²å»ºç«‹")

                    elif event == ServerEvent.SESSION_STARTED:
                        dialog_id = payload_msg.get('dialog_id', '')
                        logger.info(f"ğŸš€ ä¼šè¯å·²å¯åŠ¨ (Dialog ID: {dialog_id[:8]}...)")

                    elif event == ServerEvent.SESSION_FINISHED:
                        logger.info("âœ… ä¼šè¯å·²ç»“æŸ")

                    elif event == ServerEvent.TTS_ENDED:
                        logger.debug("ğŸµ TTSéŸ³é¢‘åˆæˆç»“æŸ")
                        self._finalize_conversation_turn()

                    elif event == ServerEvent.ASR_INFO:
                        logger.info("ğŸ¤ ASR_INFO: å·²æ¸…ç©ºéŸ³é¢‘ç¼“å†²åŒº (ç”¨æˆ·æ‰“æ–­)")
                        self.is_user_speaking = True
                        self.is_ai_responding = False
                        self.current_user_text = ""
                        self._update_console_display()

                    elif event == ServerEvent.ASR_RESPONSE:
                        logger.info(f"ğŸ¤ ASR_RESPONSE: æ”¶åˆ°è¯­éŸ³è¯†åˆ«å“åº”")
                        results = payload_msg.get('results', [])
                        if results and len(results) > 0:
                            text = results[0].get('text', '')
                            is_interim = results[0].get('is_interim', False)
                            logger.info(f"ğŸ‘¤ ç”¨æˆ·è¯­éŸ³è¯†åˆ«: '{text}' (ä¸´æ—¶: {is_interim})")
                            if text and text.strip():
                                self.current_user_text = text
                                self._update_console_display()
                        else:
                            logger.warning("âš ï¸ ASR_RESPONSEä¸­æ— resultsæˆ–resultsä¸ºç©º")

                    elif event == ServerEvent.ASR_ENDED:
                        logger.info("ğŸ¤ ASR_ENDED: è¯­éŸ³è¯†åˆ«ç»“æŸ")
                        self.is_user_speaking = False
                        if self.current_user_text and self.current_user_text.strip():
                            self._update_console_display(final_user=True)

                    elif event == ServerEvent.CHAT_RESPONSE:
                        content = payload_msg.get('content', '')
                        if content and content.strip():
                            if not self.is_ai_responding:
                                self.is_ai_responding = True
                                self.current_ai_text = ""
                                self.last_displayed_ai_text = ""
                            self.current_ai_text += content
                            if len(self.current_ai_text) - len(self.last_displayed_ai_text) >= 5 or content.endswith(
                                    ('ã€‚', 'ï¼', 'ï¼Ÿ', 'ï¼Œ', 'ã€')
                                    ):
                                self._update_console_display()
                            logger.debug(f"ğŸ¤– AIæ–‡æœ¬å›å¤: '{content}' â†’ æ€»è®¡: '{self.current_ai_text[:50]}...'")
                    elif event == ServerEvent.CHAT_ENDED:
                        logger.debug("ğŸ¤– AIæ–‡æœ¬å›å¤ç»“æŸ")
                        self.is_ai_responding = False

                elif response['message_type'] == 'SERVER_ERROR':
                    logger.error(f"æœåŠ¡å™¨é”™è¯¯: {response['payload_msg']}")
                    raise Exception("æœåŠ¡å™¨é”™è¯¯")

        except Exception as e:
            logger.warning(f"failed to pull, reason: {e}")

    async def thread_client2server(self):
        seq = 0
        try:
            while self.is_running and self.audio_adapter.is_running:
                seq += 1
                logger.debug(f"pushing ({seq})")
                chunk = await self.audio_adapter.get_next_client_chunk()
                if chunk:
                    await self.volcengine_client.push_audio(chunk)
                await asyncio.sleep(0.01)
        except Exception as e:
            logger.warning(f"failed to push, reason: {e}")

    async def _request_say_hello(self):
        await self.volcengine_client.request_say_hello(VOLCENGINE_WELCOME)

    def _create_audio_adapter(self, adapter_mode: AdapterMode) -> AdapterBase:
        """åˆ›å»ºéŸ³é¢‘IOå®ä¾‹"""

        def handle_audio_input(audio_data: bytes) -> None:
            """å¤„ç†éŸ³é¢‘è¾“å…¥æ•°æ®"""
            if not self.is_running or not self.volcengine_client.is_active:
                return
            asyncio.create_task(self.volcengine_client.push_audio(audio_data))

        def on_adapter_prepared() -> None:
            """éŸ³é¢‘IOå‡†å¤‡å°±ç»ªå›è°ƒ"""
            logger.info("ğŸ¯ WebRTCè¿æ¥å·²å»ºç«‹ï¼Œå‘é€SayHello")
            # è®¾ç½®æ ‡å¿—ï¼Œåœ¨ä¸»äº‹ä»¶å¾ªç¯ä¸­å‘é€say-hello
            self._should_send_hello = True

        if adapter_mode == AdapterMode.system:
            from src.io_adapters.system.adapter import SystemAdapter
            return SystemAdapter()

        if adapter_mode == AdapterMode.webrtc:
            from src.io_adapters.webrtc.adapter import WebRTCAdapter
            from src.config import webrtc_config
            adapter = WebRTCAdapter(webrtc_config)
            # è®¾ç½®WebRTCå‡†å¤‡å°±ç»ªå›è°ƒ
            adapter._on_prepared = on_adapter_prepared
            return adapter

        raise Exception(f"invalid adapter mode: {adapter_mode}")

    def _display_subtitle(self, ai_text: str = "", is_final: bool = False):
        """æ˜¾ç¤ºå­—å¹•"""
        pass  # ç®€åŒ–å®ç°

    def _clear_current_line(self):
        """æ¸…é™¤å½“å‰è¡Œ"""
        print("\r\033[K", end="", flush=True)

    def _update_console_display(self, final_user: bool = False, final_ai: bool = False):
        """æ›´æ–°æ§åˆ¶å°æ˜¾ç¤º"""
        with self.subtitle_lock:
            if final_user and self.current_user_text:
                self._clear_current_line()
                print(f"ğŸ‘¤ ç”¨æˆ·: {self.current_user_text}")
                return
            elif final_ai and self.current_ai_text:
                self._clear_current_line()
                print(f"ğŸ¤– AI: {self.current_ai_text}")
                self.last_displayed_ai_text = self.current_ai_text
                return

            if self.is_user_speaking and self.current_user_text:
                self._clear_current_line()
                display_text = self.current_user_text[:150] + "..." if len(
                    self.current_user_text
                    ) > 150 else self.current_user_text
                print(f"ğŸ‘¤ ç”¨æˆ·: {display_text}", end="", flush=True)
            elif self.is_ai_responding and self.current_ai_text:
                if self.current_ai_text != self.last_displayed_ai_text:
                    self._clear_current_line()
                    display_text = self.current_ai_text[:150] + "..." if len(
                        self.current_ai_text
                        ) > 150 else self.current_ai_text
                    print(f"ğŸ¤– AI: {display_text}", end="", flush=True)
                    self.last_displayed_ai_text = self.current_ai_text
            elif not self.is_user_speaking and not self.is_ai_responding:
                self._clear_current_line()
                print("ğŸ™ï¸ è¯·è¯´è¯...", end="", flush=True)

    def _finalize_conversation_turn(self):
        """å®Œæˆä¸€è½®å¯¹è¯"""
        with self.subtitle_lock:
            if self.current_user_text or self.current_ai_text:
                if self.current_ai_text and self.current_ai_text != self.last_displayed_ai_text:
                    self._clear_current_line()
                    print(f"ğŸ¤– AI: {self.current_ai_text}")

                self.conversation_history.append(
                    {
                        'user': self.current_user_text,
                        'ai': self.current_ai_text,
                        'timestamp': time.time()
                        }
                    )

                self.current_user_text = ""
                self.current_ai_text = ""
                self.last_displayed_ai_text = ""
                self.is_user_speaking = False
                self.is_ai_responding = False

                print(f"\n{'â”€' * 50}")
                print(f"ğŸ“Š ç¬¬{len(self.conversation_history)}è½®å¯¹è¯ | â° {time.strftime('%H:%M:%S')}")
                print(f"{'â”€' * 50}\n")
                print("ğŸ™ï¸ è¯·è¯´è¯...", end="", flush=True)

    def _keyboard_signal(self, sig, frame):
        logger.info("ğŸ‘‹ æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
        self.is_running = False
        # ç¡®ä¿éŸ³é¢‘é€‚é…å™¨ä¹Ÿåœæ­¢
        if hasattr(self, 'audio_adapter') and self.audio_adapter:
            self.audio_adapter.is_running = False
            # å¦‚æœæ˜¯ WebRTC é€‚é…å™¨ï¼Œéœ€è¦åœæ­¢ WebRTC ç®¡ç†å™¨
            if hasattr(self.audio_adapter, '_webrtc_manager') and self.audio_adapter._webrtc_manager:
                self.audio_adapter._webrtc_manager.is_running = False
                logger.info("å·²è®¾ç½®WebRTCåœæ­¢æ ‡å¿—")

        logger.info("ä¿¡å·å¤„ç†å®Œæˆ")
